{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Machine Learning (2022), exercises\n",
    "\n",
    "\n",
    "## General instructions for all exercises\n",
    "\n",
    "Follow the instructions and fill in your solution under the line marked by tag\n",
    "\n",
    "> YOUR CODE HERE\n",
    "\n",
    "Remove also line \n",
    "\n",
    "> raise NotImplementedError()\n",
    "\n",
    "**Do not change other areas of the document**, since it may disturb the autograding of your results!\n",
    "  \n",
    "Having written the answer, execute the code cell by and pressing `Shift-Enter` key combination. The code is run, and it may print some information under the code cell. The focus automatically moves to the next cell and you may \"execute\" that cell by pressing `Shift-Enter` again, until you have reached the code cell which tests your solution. Execute that and follow the feedback. Usually it either says that the solution seems acceptable, or reports some errors. You can go back to your solution, modify it and repeat everything until you are satisfied. Then proceed to the next task.\n",
    "   \n",
    "Repeat the process for all tasks.\n",
    "\n",
    "The notebook may also contain manually graded answers. Write your manually graded answer under the line marked by tag:\n",
    "\n",
    "> YOUR ANSWER HERE\n",
    "\n",
    "Manually graded tasks are text in markdown format. It may contain text, pseudocode, or mathematical formulas. You can write formulas with $\\LaTeX$-syntax by enclosing the formula with dollar signs (`$`), for example `$f(x)=2 \\pi / \\alpha$`, will produce $f(x)=2 \\pi / \\alpha$\n",
    "\n",
    "When you have passed the tests in the notebook, and you are ready to submit your solutions, download the whole notebook, using menu `File -> Download as -> Notebook (.ipynb)`. Save the file in your hard disk, and submit it in [Moodle](https://moodle.uwasa.fi) or EUNICE Moodle under the corresponding excercise.\n",
    "\n",
    "Your solution should be an executable Python code. Use the code already existing as an example of Python programing and read more from the numerous Python programming material from the Internet if necessary. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ac0abf8467c557f3b5a0227eb266ce3a",
     "grade": false,
     "grade_id": "cell-0bd9bf369d15fc72",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Reading, and visualizing data with pandas\n",
    "\n",
    "This exercise contains the following tasks:\n",
    "\n",
    "1. Read the CSV data to Pandas dataframe\n",
    "1. Study the data statistics \n",
    "1. Slice and plot Finnish Covid cases\n",
    "1. Parse timestamps from strings\n",
    "1. Differentiate the data to get daily cases\n",
    "1. Store the data in four different formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T06:49:33.873576Z",
     "start_time": "2022-10-14T06:49:33.096319Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ef54ec85a55c1d824ba9f0a8a209bbb",
     "grade": false,
     "grade_id": "cell-4fd5279efd07c830",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "# This makes the plots to have white background and grids by default\n",
    "#plt.style.use('seaborn-whitegrid')\n",
    "sns.set()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0202f55d9ee363433e0314deceb218f9",
     "grade": false,
     "grade_id": "cell-13bde4d9e4eb3309",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Task 1: Read and examine data\n",
    "#### a) Read the CSV data to Pandas dataframe\n",
    "\n",
    "Read the data file `time_series_covid19_confirmed.csv` to a pandas dataframe called `D`, and display the head and tail of the dataframe.\n",
    "\n",
    "The data is taken from [GitHub](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data) and it is collected by John Hopkins hospital, USA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T06:49:33.930250Z",
     "start_time": "2022-10-14T06:49:33.874935Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a65685ae10a6af139e7f3853fdfbbbd",
     "grade": false,
     "grade_id": "cell-f847b9b64c459963",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T06:49:33.933810Z",
     "start_time": "2022-10-14T06:49:33.931288Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "762e8a51cd5e094628e2cdd6b862184a",
     "grade": true,
     "grade_id": "cell-4921356b2337c8ff",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Some testing\n",
    "assert(D.shape == (289,993)), \"The shape of the data does not seem to be correct\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1 b) Missing values\n",
    "What would be the best strategy to mitigate missing values if we are interested only in Finnish situation? Drop rows with missing values, Drop columns with missing values or impute missing values with empty values?\n",
    "\n",
    "Go ahead and apply the necessary cleaning operation to D and store the result as D1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T06:49:33.954673Z",
     "start_time": "2022-10-14T06:49:33.935224Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "324464db1d2cabc8c6563d5115b11d07",
     "grade": false,
     "grade_id": "cell-1f28c244a918f971",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T06:49:33.989380Z",
     "start_time": "2022-10-14T06:49:33.955745Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b18ef2de51235127ce04c9848ac91180",
     "grade": true,
     "grade_id": "cell-c9187acbac20ef8f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Some testing\n",
    "if 'D1' not in globals():\n",
    "    print(\"store your modified dataframe using name D1, please\")\n",
    "    assert(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0e1569e8d5b653a113ced3f982ef827d",
     "grade": false,
     "grade_id": "cell-50d2869d3a3a4b41",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Task 2: Slice and plot Finnish Covid cases\n",
    "\n",
    "Select the data to represent confirmed Covid cases in Finland, by selecting the right row, and only those columns, which shows the numbers of cases (all columns except first four). The dataframe which has only one column, is naturally a Pandas Data Series. It is always a column vector, so transpose is not needed.\n",
    "\n",
    "You can also select it show that the result is a DataFrame, with one row. In this case transpose the selected slice of the Dataframe, using transpose operator `.T`. This makes rows to become columns and columns to become rows, just like the transpose of a Matrix in mathematics. You can chain the `.loc`, `.iloc` and `.T` operators in one line to accomplish your task.\n",
    "\n",
    "Check after selecting the slice of the original DataFrame did you got a DataFrame or series, using `type(DF)`.\n",
    "\n",
    "Save this resulting one-column dataframe by name `DF` in the workspace, and plot it using `.plot()` -function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T06:49:34.276898Z",
     "start_time": "2022-10-14T06:49:33.992758Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3f451f1e2e02b982b6953cca324ee36",
     "grade": false,
     "grade_id": "cell-384aa526eb314739",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "type(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T06:49:34.292974Z",
     "start_time": "2022-10-14T06:49:34.281835Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "732a98e22feec36a366ebdf5bc006606",
     "grade": true,
     "grade_id": "cell-dd2991cc709c91d5",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# The result can be either DataFrame with only one column or a dataSeries, which have always only one column\n",
    "\n",
    "if type(DF)==pd.core.frame.DataFrame:\n",
    "    if(DF.shape[1]>1):\n",
    "        print(\"Remove unnecessary countries, please\")\n",
    "    assert(DF.shape==(989,1))\n",
    "\n",
    "if type(DF)==pd.core.series.Series:\n",
    "    if(DF.shape[0]>989):\n",
    "        print(\"Please remove also non-numerical columns from the beginning. Otherwise you cannot cleanly plot the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "edf3889aa8e38863bf5c24eeb7e8bbab",
     "grade": false,
     "grade_id": "cell-3891aad33a622798",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Task 3: Parse timestamps to datetime objects\n",
    "The data looks familiar and would be usefull already for many purposes, but it has still a problem. This is obviously a time series, but the computer does not yet understand what the values in time-axis are, and they are handled just strings without meaning. \n",
    "\n",
    "To let the computer understand them, they needs to be parsed to datetime objects. Any string can be parsed to datetime using string parser function, called `strptime()`. It uses a template for mathing a string to years (`%y`), months (`%m`) and days (`%d`). See more exact description from the [documentation](https://www.programiz.com/python-programming/datetime/strptime).\n",
    "\n",
    "The function for parsing the timestamp strings is provided below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T06:49:34.306170Z",
     "start_time": "2022-10-14T06:49:34.297815Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b5cf61719923a80d91c7e6d94a03e2a4",
     "grade": false,
     "grade_id": "cell-99dbc583693250d4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#task4\n",
    "indexes=DF.index\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Parse a timestamp\n",
    "def parseTime(s):\n",
    "    return datetime.strptime(s, \"%m/%d/%y\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "67b047ab970f0791d94597ed3bfefd77",
     "grade": false,
     "grade_id": "cell-c05cbc4e0d3ffe40",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Replace the index of `DF` by parsing the list of values in it into list of datetime objects, and assign it to the new index. \n",
    "\n",
    "You can read the values of the current index, using a read/write property `.index` of the dataframe, and you can update the index by assigning a list of datetime objects into it. \n",
    "\n",
    "You can apply the previous `parseTime()`-function to all values in a list of date-strings by using a `map()` function in python as follows\n",
    "\n",
    " `map(parseTime, listOfStringValues)`\n",
    " \n",
    " See more from [documentation](https://www.programiz.com/python-programming/methods/built-in/map).\n",
    " \n",
    " Note that if you try to run it again, it will give you an error, since the index values are no longer strings, which could be parsed again.\n",
    " \n",
    " Now plot the data again, and you will notice that the computer now understands the time axis and can show it differently.\n",
    " \n",
    " Try to slice the data and only plot the values for August 2022 (`DF.loc['yyyy-mm']`). See how the time axis is scaled again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T06:49:34.705433Z",
     "start_time": "2022-10-14T06:49:34.313049Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3232bd148b0659933f0a087d4ffbef88",
     "grade": false,
     "grade_id": "cell-04ebd028e3a77d06",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T06:49:34.711362Z",
     "start_time": "2022-10-14T06:49:34.707095Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1817795a641b8d585d90cdaf4d1924c1",
     "grade": true,
     "grade_id": "cell-f5f06c8b398ff91e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if type(DF)==pd.core.frame.DataFrame:\n",
    "    assert(DF.loc['2022-09-20'].values[0]==1277473)\n",
    "else:\n",
    "    assert(DF.loc['2022-09-20']==1277473)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2c33740b1ab212262952a3d7e4e1f74e",
     "grade": false,
     "grade_id": "cell-786420cd5eec7cd0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Task 4: Differentiate to get the daily cases\n",
    "\n",
    "Now calculate the daily cases, by calculating the difference of the cumulative number of confirmed cases, using the `.diff()` function of the dataframe as name `daily`, and plot it. \n",
    "\n",
    "If you have time, you can also smooth the daily graph by using a rolling average (`.rolling()`), and plot the smoothed curve in different plot or the same plot. See examples from:\n",
    "- Pandas [diff function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.diff.html)\n",
    "- Pandas [rolling function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rolling.html)\n",
    "\n",
    "Tip: If you want to plot both graphs in one figure, let the first plot return an axis object `ax` and define the new plot to use that same axis, as follows:\n",
    "\n",
    "`\n",
    "ax = daily. ... .plot(...)\n",
    "daily. ... .plot(ax=ax)\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T06:49:34.962879Z",
     "start_time": "2022-10-14T06:49:34.712343Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2312370814571dd7575a08ba0db29ef",
     "grade": false,
     "grade_id": "cell-5eb1bffa3a0c4d15",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T06:49:34.966696Z",
     "start_time": "2022-10-14T06:49:34.963873Z"
    }
   },
   "outputs": [],
   "source": [
    "type(daily)\n",
    "#daily.loc['2020-09-23']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T06:49:34.972409Z",
     "start_time": "2022-10-14T06:49:34.967636Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6fe9d10275d1e7b9e3afd63d9301d7b6",
     "grade": true,
     "grade_id": "cell-4212a0eb49229648",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if type(daily)==pd.core.frame.DataFrame:\n",
    "    assert(daily.shape==(989,1)), \"The shape of the differentiated data does not seem right\"\n",
    "    print(daily.loc['2020-09-23'])\n",
    "    assert(daily.loc['2020-09-23'].values[0]==110)\n",
    "else:\n",
    "    assert(daily.shape[0]==989), \"The shape of the differentiated data does not seem right\"\n",
    "    print(daily.loc['2020-09-23'])\n",
    "    assert(daily.loc['2020-09-23']==110)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e3d588c12b4500e3749426515b5b5bd1",
     "grade": false,
     "grade_id": "cell-c41aef2181959a13",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Task 5: Save the parsed data to different formats\n",
    "\n",
    "Save the parsed dataframe, DF, in different formats:\n",
    " - CSV, use function `.to_csv()`, read documentation inline or from [net](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html), use filename `cases.csv`\n",
    " - feather, use function `.to_feather()`, read documentation inline or from [net](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_feather.html), use filename `cases.feather`\n",
    " - JSON, use function `.to_json()`, read documentation inline or from [net](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_json.html), use filename `cases.csv`\n",
    "\n",
    "\n",
    " Feather and JSON do not support datetime objects as index. To overcome this issue, a new index consisting of only integers is created, and the dat is moved to the separate column. This can be accomplished by simply calling the `.reset_index()` from the dataframe.\n",
    " \n",
    " In addition, Feather requires valid column names, so they needs to be defined too, which is a good idea anyway. The column names can be set using read/write property `.columns`:\n",
    " \n",
    " Both requirements can be set as follows:\n",
    " \n",
    " `\n",
    " DFR = DF.reset_index()\n",
    " DFR.columns=('Date', 'Cases')\n",
    " `\n",
    " \n",
    "**See the code in the validation section for reading the files back.**\n",
    "\n",
    "**Note** If you do this at home, install `pyarrow` to support feather-format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T06:49:35.255909Z",
     "start_time": "2022-10-14T06:49:34.973439Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4cdbbb9cb6ad74664feead24958c019b",
     "grade": false,
     "grade_id": "cell-b27e4684e9b154f6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T06:49:35.320465Z",
     "start_time": "2022-10-14T06:49:35.257993Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "118d2df96c68b244d34a32a7bd1645c5",
     "grade": true,
     "grade_id": "cell-91e78d230d52fb4c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data_csv=pd.read_csv('cases.csv')\n",
    "data_fea=pd.read_feather('cases.feather')\n",
    "data_json=pd.read_json('cases.json')\n",
    "\n",
    "assert((data_csv.shape==(989,2)) or (data_csv.shape==(989,3)))\n",
    "assert((data_fea.shape==(989,1)) or (data_fea.shape==(989,2)))\n",
    "assert((data_json.shape==(989,1)) or (data_json.shape==(989,2)))\n",
    "\n",
    "# Check the types of the datetime column values\n",
    "assert((type(data_csv.iloc[1,0])==str) or (type(data_csv.iloc[1,1])==str))\n",
    "assert((type(data_json.index[0])==pd.Timestamp) or (type(data_json.iloc[1,0])==pd.Timestamp))\n",
    "assert(type(data_fea.iloc[1,0])==pd.Timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "75aefc37c6dca9e57f3690f29e6cf7fa",
     "grade": false,
     "grade_id": "cell-140553854483d1cf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note that the binary data formats retain the timestamps objects as timestamps, whereas after reading CSV, the timestamps needs to be parsed again to timestamps.\n",
    "\n",
    "To help deciding which format to use in your own projects, take a look at the \n",
    "[comparison of different file formats](https://towardsdatascience.com/the-best-format-to-save-pandas-data-414dca023e0d). The optimal file format depends also on the application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
